# -*- coding: utf-8 -*-
"""Github PH 245 Final Project

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HjMxYXxtAicbSTy2_gEg9ucIQhnM51AL
"""

import time
import math
import os
import os.path
import numpy as np
import pandas as pd
import io
from google.colab import files
os.getcwd()
uploaded = files.upload()

df_immunization = pd.read_csv('NISPUF17.csv')
df_immunization.head()

#df_immunization.PU431331.value_counts()

df_immunization = pd.read_csv('NISPUF17.csv')

#only include people with PDAT == 1
df_immunization = df_immunization[df_immunization.PDAT == 'CHILD HAS ADEQUATE PROVIDER DATA OR ZERO VACCINATIONS']

#drop people of unknown poverty status
df_immunization = df_immunization[df_immunization.INCPOV1 != 'UNKNOWN']

#rename to form the IMMUNE column
df_immunization.rename(columns={'PU431331':'IMMUNE'}, inplace=True)

#recode IMMUNE as 0 or 1 (Up to date)
df_immunization['IMMUNE'] = df_immunization['IMMUNE'].map({'UTD': 1, 'NOT UTD': 0})

#recode census region
df_immunization['CEN_REG'] = df_immunization['CEN_REG'].map({'WEST': 1, 'MIDWEST': 2, 'NORTHEAST': 3, 'SOUTH': 4})

#create dummy variables of categorical features
df_immunization = pd.get_dummies(df_immunization, columns=['FRSTBRN','CEN_REG', 'EDUC1', 'INCPOV1', 'M_AGEGRP2', 'RACEETHK', 'INS_STAT2_I','CHILDNM','CWIC_01'], prefix = ['FRSTBRN','CEN_REG', 'EDUC1', 'INCPOV1', 'M_AGEGRP2', 'RACEETHK', 'INS_STAT2_I','CHILDNM','CWIC_01'])

#name the pred_columns group
pred_columns = ['FRSTBRN_1',	'FRSTBRN_2','CEN_REG_1'	, 'CEN_REG_2'	,'CEN_REG_3',	'CEN_REG_4', 'EDUC1_1',	'EDUC1_2',	'EDUC1_3',	'EDUC1_4', 'INCPOV1_1',	'INCPOV1_2',	'INCPOV1_3', 'M_AGEGRP2_1',	'M_AGEGRP2_2'	, 'RACEETHK_1',	'RACEETHK_2',	'RACEETHK_3',	'RACEETHK_4', 'INS_STAT2_I_1',	'INS_STAT2_I_2',	'INS_STAT2_I_3',	'INS_STAT2_I_4','BF_ENDR06', 'CHILDNM_1',	'CHILDNM_2', 	'CHILDNM_3'	,'CWIC_01_1',	'CWIC_01_2', 'IMMUNE']

#shrink df to only include predictors and target
relevant_columns = ['FRSTBRN_1',	'FRSTBRN_2','CEN_REG_1'	, 'CEN_REG_2'	,'CEN_REG_3',	'CEN_REG_4', 'EDUC1_1',	'EDUC1_2',	'EDUC1_3',	'EDUC1_4', 'INCPOV1_1',	'INCPOV1_2',	'INCPOV1_3', 'M_AGEGRP2_1',	'M_AGEGRP2_2'	, 'RACEETHK_1',	'RACEETHK_2',	'RACEETHK_3',	'RACEETHK_4', 'INS_STAT2_I_1',	'INS_STAT2_I_2',	'INS_STAT2_I_3',	'INS_STAT2_I_4','BF_ENDR06', 'CHILDNM_1',	'CHILDNM_2', 	'CHILDNM_3'	,'CWIC_01_1',	'CWIC_01_2', 'IMMUNE']

#drop NA rows
df_immunization = df_immunization[relevant_columns]
df_immunization = df_immunization.dropna()

#name columns to scale
scaled_columns = ['BF_ENDR06']

df_immunization.describe
df_immunization

df_immunization.isnull().sum()

df_immunization.head()

from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler, StandardScaler, RobustScaler, PowerTransformer
from sklearn.model_selection  import train_test_split, cross_val_score, cross_val_predict, KFold, GridSearchCV

print(df_immunization.describe())
scaler = MinMaxScaler()

scaler.fit(df_immunization[scaled_columns]) #Transform indexes to min max scaling
df_immunization[scaled_columns]=scaler.transform(df_immunization[scaled_columns])

# Create a y dataset with just label variable
df_y=df_immunization['IMMUNE']
df_x=df_immunization[pred_columns]

df_x.shape

### Split into training and test set
X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.2, random_state=42)

# Commented out IPython magic to ensure Python compatibility.
from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier, RandomForestRegressor, RandomForestClassifier 

def rfr_model(X, y):# Perform Grid-Search
    scores=['roc_auc']
    param_grid ={
    'max_depth': list(range(2,10)),
    'n_estimators': (50, 100, 500, 1000, 3000)
    }
    for score in scores:
        clf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring=score)
        grid_result=clf.fit(X, y)
        best_params = grid_result.best_params_
        print("Best parameters set found on development set:")
        print()
        print(clf.best_params_)
        print()
        print("Grid scores on development set:")
        print()
        means = clf.cv_results_['mean_test_score']
        stds = clf.cv_results_['std_test_score']
        for mean, std, params in zip(means, stds, clf.cv_results_['params']):
            print("%0.3f (+/-%0.03f) for %r"
#                   % (mean, std * 2, params))
        print()
    return grid_result

# Commented out IPython magic to ensure Python compatibility.
import xgboost as xgb
from xgboost import XGBClassifier

def gbc_model(X, y):# Perform Grid-Search on gradient boosted model 
    scores=['roc_auc']
    param_grid ={
    'learning_rate': (.01, .05 ,.1 ,.2, .3, .7),
    'max_depth': list(range(2,10))
    }
    for score in scores:
        clf = GridSearchCV(xgb.XGBClassifier(random_state=42), param_grid, cv=5, scoring=score)
        grid_result=clf.fit(X, y)
        best_params = grid_result.best_params_
        print("Best parameters set found on development set:")
        print()
        print(clf.best_params_)
        print()
        print("Grid scores on development set:")
        print()
        means = clf.cv_results_['mean_test_score']
        stds = clf.cv_results_['std_test_score']
        for mean, std, params in zip(means, stds, clf.cv_results_['params']):
            print("%0.3f (+/-%0.03f) for %r"
#                   % (mean, std * 2, params))
        print()
    return grid_result

# Commented out IPython magic to ensure Python compatibility.
from sklearn.svm import SVC

def sv_model(X, y): #SupportVectorClassifier
    gammas =  [.0001, 0.001, 0.01, 0.1, 1, 10, 100, ]
    Cs=[.001, .01, .1, 1, 10]
    param_grid={
            'gamma': gammas,
            'C':Cs}
    scores=['roc_auc']
    for score in scores:
        clf = GridSearchCV(SVC(probability=True ), param_grid, cv=5, scoring=score)
        grid_result=clf.fit(X, y)
        best_params = grid_result.best_params_
        print("Best parameters set found on development set:")
        print()
        print(clf.best_params_)
        print()
        print("Grid scores on development set:")
        print()
        means = clf.cv_results_['mean_test_score']
        stds = clf.cv_results_['std_test_score']
        for mean, std, params in zip(means, stds, clf.cv_results_['params']):
            print("%0.3f (+/-%0.03f) for %r"
#                   % (mean, std * 2, params))
        print()
    return grid_result

# Commented out IPython magic to ensure Python compatibility.
from sklearn.neural_network import MLPClassifier

def nn_model(X, y): #neuralnetwork
    alphas =  [0.00001, 0.0001, 0.001, 0.01, 0.1, ]
    solvers = ['lbfgs', 'sgd', 'adam']
    activations=['identity', 'logistic', 'tanh', 'relu']
    param_grid={
            'alpha': alphas,
            'solver': solvers,
            'activation':activations}
    scores=['roc_auc']
    for score in scores:
        clf = GridSearchCV(MLPClassifier(random_state=42), param_grid, cv=5, scoring=score)
        grid_result=clf.fit(X, y)
        best_params = grid_result.best_params_
        print("Best parameters set found on development set:")
        print()
        print(clf.best_params_)
        print()
        print("Grid scores on development set:")
        print()
        means = clf.cv_results_['mean_test_score']
        stds = clf.cv_results_['std_test_score']
        for mean, std, params in zip(means, stds, clf.cv_results_['params']):
            print("%0.3f (+/-%0.03f) for %r"
#                   % (mean, std * 2, params))
        print()
    return grid_result

import statsmodels.api as sm

#check for correlation
df_x.corr()


#first logit model
logit_model_1 = sm.Logit(df_y,df_x)
result = logit_model_1.fit()
print(result.summary2())

#second logit model, removing insignificant features
y_2 = df_immunization[['IMMUNE']]
X_2 = df_immunization[['CEN_REG', 'EDUC1', 'FRSTBRN', 'INCPOV1', 'M_AGEGRP2',
                #     'INS_STAT2_I', 'BF_ENDR06']]
logit_model_2 = sm.Logit(y_2,X_2)
result = logit_model_2.fit()
print(result.summary2())

#COMMENT IN to TRAIN

rfr_grid=rfr_model(X_train, y_train)

gbc_grid=gbc_model(X_train, y_train)

sv_grid=sv_model(X_train, y_train)

nn_grid=nn_model(X_train, y_train)

#COMMENT IN if training

#gbc parameters
best_max_depth_gbc=gbc_grid.best_params_["max_depth"] #
best_learning_rate=gbc_grid.best_params_["learning_rate"] #

#svc parameters
best_gamma=sv_grid.best_params_["gamma"] #
best_c_sv=sv_grid.best_params_["C"] #

#random forest parameters
best_max_depth_rf=rfr_grid.best_params_['max_depth']
best_n_estimators_rf=rfr_grid.best_params_['n_estimators']

#ffnn parameters
best_activation=nn_grid.best_params_['activation'] #
best_alpha=nn_grid.best_params_['alpha'] #
best_solver=nn_grid.best_params_['solver'] #

print(best_max_depth_gbc)
print(best_learning_rate)
print("---")
print(best_gamma)
print(best_c_sv)
print("---")
print(best_max_depth_rf)
print(best_n_estimators_rf)
print("---")
print(best_activation)
print(best_alpha)
print(best_solver)

# COMMENT OUT IF TRAINING
best_max_depth_gbc=2
best_learning_rate=.01

best_gamma= 0.0001
best_c_sv= 0.01

best_max_depth_rf=2
best_n_estimators_rf=50

best_activation='relu'
best_alpha=0.1
best_solver='adam'

from sklearn.linear_model import LogisticRegression
from sklearn import metrics

RF_clf =RandomForestClassifier(max_depth=best_max_depth_rf, n_estimators=best_n_estimators_rf, 
                               random_state=42, warm_start=True, oob_score=True)
SV_clf =  SVC(gamma=best_gamma, C=best_c_sv, random_state=42, probability=True)
GBC_clf =  xgb.XGBClassifier(learning_rate=best_learning_rate, random_state=42, max_depth=best_max_depth_gbc)
LR_clf=LogisticRegression(random_state=42)
NN_clf = MLPClassifier(activation=best_activation, alpha=best_alpha, solver=best_solver, random_state=42)



X_train, X_test, y_train, y_test = train_test_split(X_2, y_2, test_size=0.3, random_state=42)
logreg = LogisticRegression(solver='lbfgs', multi_class='auto')
logreg.fit(X_train, y_train.values.ravel())

RF_clf.fit(X_train, y_train.values.ravel())
print("Random Forest model score: %.3f" % RF_clf.score(X_test, y_test.values.ravel()))

SV_clf.fit(X_train, y_train.values.ravel())
print("SVC model score: %.3f" % SV_clf.score(X_test, y_test.values.ravel()))

GBC_clf.fit(X_train, y_train.values.ravel())
print("Gradient Boosting Classifier model score: %.3f" % GBC_clf.score(X_test, y_test.values.ravel()))

NN_clf.fit(X_train, y_train.values.ravel())
print("Neural Network Classifier model score: %.3f" % NN_clf.score(X_test, y_test.values.ravel()))

y_pred = logreg.predict(X_test)
print('Logistic regression model score: %.3f' %
logreg.score(X_test, y_test))

from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, auc
import matplotlib as mpl
import matplotlib.pyplot as plt
from matplotlib import pyplot

y_score=GBC_clf.predict_proba(X_test)
y_score=y_score[:,1]
fpr, tpr, thresholds = roc_curve(y_test, y_score)
roc_auc = roc_auc_score(y_test, y_score)
print('AUC: %.3f' % roc_auc)
# Plot ROC curve
plt.figure(figsize=(16, 12))
plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate (1 - Specificity)', size=16)
plt.ylabel('True Positive Rate (Sensitivity)', size=16)
plt.title('ROC Curve Gradient Boosting Classifier', size=20)
plt.savefig('GBC_ROC')
plt.legend(fontsize=14);

y_score=RF_clf.predict_proba(X_test)
y_score=y_score[:,1]
fpr, tpr, thresholds = roc_curve(y_test, y_score)
roc_auc = roc_auc_score(y_test, y_score)
print('AUC: %.3f' % roc_auc)
# Plot ROC curve
plt.figure(figsize=(16, 12))
plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate (1 - Specificity)', size=16)
plt.ylabel('True Positive Rate (Sensitivity)', size=16)
plt.title('ROC Curve Random Forest Classifier', size=20)
plt.savefig('RF_ROC')
plt.legend(fontsize=14);

y_score=SV_clf.predict_proba(X_test)
y_score=y_score[:,1]
fpr, tpr, thresholds = roc_curve(y_test, y_score)
roc_auc = roc_auc_score(y_test, y_score)
print('AUC: %.3f' % roc_auc)
# Plot ROC curve
plt.figure(figsize=(16, 12))
plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate (1 - Specificity)', size=16)
plt.ylabel('True Positive Rate (Sensitivity)', size=16)
plt.title('ROC Curve Support Vector Classifier', size=20)
plt.savefig('SVC_ROC')
plt.legend(fontsize=14);

y_score=NN_clf.predict_proba(X_test)
y_score=y_score[:,1]
fpr, tpr, thresholds = roc_curve(y_test, y_score)
roc_auc = roc_auc_score(y_test, y_score)
print('AUC: %.3f' % roc_auc)
# Plot ROC curve
plt.figure(figsize=(16, 12))
plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate (1 - Specificity)', size=16)
plt.ylabel('True Positive Rate (Sensitivity)', size=16)
plt.title('ROC Curve Neural Network Classifier', size=20)
plt.savefig('NN_ROC')
plt.legend(fontsize=14);

logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))
fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])
#plot ROC curve
plt.figure(figsize=(16,12))
plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % logit_roc_auc)
plt.plot([0, 1], [0, 1],'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate (1 - Specificity)', size = 16)
plt.ylabel('True Positive Rate (Sensitivity)', size = 16)
plt.title('ROC Curve Logistic Regression', size = 20)
plt.legend(loc="upper left", fontsize=14)
plt.savefig('Log_ROC')
plt.show()

SV_y_pred=SV_clf.predict(X_test)
GBC_y_pred=GBC_clf.predict(X_test)
RF_y_pred=RF_clf.predict(X_test)
NN_y_pred=NN_clf.predict(X_test)


print("Random Forest confusion matrix")
print(confusion_matrix(y_test.values, RF_y_pred))

print("Gradient Boosting Classifier confusion matrix")
print(confusion_matrix(y_test.values, GBC_y_pred))

print("Support Vector Classifier confusion matrix")
print(confusion_matrix(y_test.values, SV_y_pred))

print("Neural Network Classifier confusion matrix")
print(confusion_matrix(y_test.values, NN_y_pred))

print("Logistic regression confusion matrix")
print(confusion_matrix(y_test, y_pred))

y_test.values.mean()

threshold = 0.15
predicted_proba_RF = RF_clf.predict_proba(X_test)
predicted_RF = (predicted_proba_RF [:,1] >= threshold).astype('int')

predicted_proba_SV = SV_clf.predict_proba(X_test)
predicted_SV = (predicted_proba_SV [:,1] >= threshold).astype('int')

predicted_proba_GBC = GBC_clf.predict_proba(X_test)
predicted_GBC = (predicted_proba_GBC [:,1] >= threshold).astype('int')

predicted_proba_NN = NN_clf.predict_proba(X_test)
predicted_NN = (predicted_proba_NN [:,1] >= threshold).astype('int')

print("Random Forest confusion matrix")
print(confusion_matrix(y_test.values, predicted_RF))

print("Gradient Boosting Classifier confusion matrix")
print(confusion_matrix(y_test.values, predicted_GBC))

print("Support Vector Classifier confusion matrix")
print(confusion_matrix(y_test.values, predicted_SV))

print("Neural Network Classifier confusion matrix")
print(confusion_matrix(y_test.values, predicted_NN))

forest = RandomForestClassifier(n_estimators=3000, max_depth=3, random_state=42)

forest.fit(X_train, y_train)
importances = forest.feature_importances_
idx = np.arange(0, X_train.shape[1]) #create an index array, with the number of features

features_to_keep=idx[importances > np.mean(importances)]
std = np.std([tree.feature_importances_ for tree in forest.estimators_],
             axis=0)
indices = np.argsort(importances)[::-1]
print (features_to_keep.shape)
# Print the feature ranking
print("Feature ranking:")

feature_list=[]
for f in range(4):
    print([X_train.iloc[:,features_to_keep].columns[f], importances[indices[f]]])
    feature_list.append(X_train.iloc[:,features_to_keep].columns[f])

feat_importances = pd.Series(forest.feature_importances_, index=X_train.columns)
feat_importances.nlargest(20).plot(kind='barh')

print(feature_list)

from sklearn.decomposition import PCA

pca=PCA()
pca.fit(X_train)
X_train_pca=pca.transform(X_train)
X_test_pca = pca.transform(X_test)

plt.plot(np.cumsum(pca.explained_variance_ratio_))
plt.xlabel('number of components')
plt.ylabel('cumulative explained variance');